{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2297cb5",
   "metadata": {},
   "source": [
    "# C. DPM Trope Clustering\n",
    "\n",
    "The algorithm proposed by the paper. Poor performance for our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e2d2845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4aa60f-ae66-477f-a6ae-bdc1cc5872d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bags_folder = os.path.abspath('data/char_bags') #Bag of words json file from build_char_word_bags.py output\n",
    "tropes_file = os.path.abspath('data/tropes/tvtropes.clusters.txt') #tropes from CMU dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ad89d5d-ec71-4e45-9698-1c23efc09979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trope_clustering.src.trope_clustering.helpers.DPM_utilities import load_character_bags\n",
    "\n",
    "#load character bags of words\n",
    "char_full = load_character_bags(bags_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e35fbc-e077-47e6-a9aa-b98bb781de81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agent features: 9291\n",
      "Number of patient features: 8627\n",
      "Number of attribute features: 16799\n",
      "Document-term matrix shape:\n",
      " (41529, 34717)\n"
     ]
    }
   ],
   "source": [
    "from trope_clustering.src.trope_clustering.helpers.DPM_utilities import get_dt_matrix\n",
    "\n",
    "dt_matrix, agent_features, patient_features, attribute_features = get_dt_matrix(char_full)\n",
    "combined_features = list(agent_features) + list(patient_features) + list(attribute_features)\n",
    "\n",
    "print(\"Number of agent features:\", len(agent_features))\n",
    "print(\"Number of patient features:\", len(patient_features))\n",
    "print(\"Number of attribute features:\", len(attribute_features))\n",
    "print(\"Document-term matrix shape:\\n\", dt_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2acd5faa-ce98-49ae-8a24-4e8892bcd6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 434\n",
      "Number of unique tropes: 72\n"
     ]
    }
   ],
   "source": [
    "from trope_clustering.src.trope_clustering.helpers.DPM_utilities import load_tropes\n",
    "\n",
    "#load character tropes\n",
    "tropes = load_tropes(tropes_file)\n",
    "print(f\"Sample size: {len(tropes)}\")\n",
    "print(f\"Number of unique tropes: {len(set(tropes.values()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d9345c9-0411-4c37-8f51-935c8cecf5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=72) \n",
    "persona_distributions = lda.fit_transform(dt_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fafbd4e2-ce50-4b5b-9656-94891bfb1582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words for the first 5 personas:\n",
      "Persona 0: ['friend', 'fall', 'new', 'best', 'have']\n",
      "Persona 1: ['crush', 'star', 'find', 'decide', 'reveal']\n",
      "Persona 2: ['captain', 'sister', 'tom', 'king', 'team']\n",
      "Persona 3: ['start', 'take', 'tell', 'leave', 'go']\n",
      "Persona 4: ['learn', 'leader', 'meet', 'sir', 'journalist']\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 words for the first 5 personas:\")\n",
    "\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    if idx > 4:\n",
    "        break\n",
    "    top_indices = topic.argsort()[-5:][::-1]\n",
    "    print(f\"Persona {idx}: {[combined_features[i] for i in top_indices]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27bbd09b-6380-45a9-964c-295a61f9dd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size of overlapping chars: 131\n"
     ]
    }
   ],
   "source": [
    "from trope_clustering.src.trope_clustering.helpers.DPM_utilities import get_overlapping_characters\n",
    "\n",
    "#update the characaters and tropes to only include ones whose trope we know and who we have the bag of words for (ie. characters included in both the bag of words dataset we have and in the trope testing set)\n",
    "char_filtered, tropes_filtered = get_overlapping_characters(char_full, tropes)\n",
    "\n",
    "print(f\"Sample size of overlapping chars: {len(tropes_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58927a3b-f129-448b-bc59-0af0273e8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trope_clustering.src.trope_clustering.helpers.DPM_utilities import get_clusters_dictionary\n",
    "cluster_dict = get_clusters_dictionary(char_full, char_filtered, persona_distributions.argmax(axis=1), len(set(tropes.values())))\n",
    "\n",
    "from trope_clustering.src.trope_clustering.helpers.DPM_utilities import get_tropes_dictionary\n",
    "grouped_by_trope = get_tropes_dictionary(tropes_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3daf879e-748c-4917-97a6-e7fc6fd6b2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darth Vader:\n",
      "\n",
      "Prediction cluster containing Darth Vader (Only showing characters who exist in tvtropes.clusters.txt):\n",
      "Cluster 22: Giacomo Casanova, Darth Vader, Guy\n",
      "\n",
      "Groundtruth cluster containing Darth Vader (Only showing characters who exist in tvtropes.clusters.txt):\n",
      "master_swordsman: Obi-Wan Kenobi, Blade, Darth Vader, Bill, Aragorn\n",
      "\n",
      "=====================\n",
      "\n",
      "Hannibal Lecter:\n",
      "\n",
      "Prediction cluster containing Hannibal Lecter (Only showing characters who exist in tvtropes.clusters.txt):\n",
      "Cluster 3: Hannibal Lecter, Harold Lee\n",
      "\n",
      "Groundtruth cluster containing Hannibal Lecter (Only showing characters who exist in tvtropes.clusters.txt):\n",
      "cultured_badass: Hannibal Lecter, Dorian Gray\n",
      "\n",
      "=====================\n",
      "\n",
      "Anakin Skywalker:\n",
      "\n",
      "Prediction cluster containing Anakin Skywalker (Only showing characters who exist in tvtropes.clusters.txt):\n",
      "Cluster 40: Captain Nemo, Mr. Kesuke Miyagi, Ashley, Anakin Skywalker\n",
      "\n",
      "Groundtruth cluster containing Anakin Skywalker (Only showing characters who exist in tvtropes.clusters.txt):\n",
      "gadgeteer_genius: Tony Stark, Lucius Fox, Anakin Skywalker, Lewis\n",
      "\n",
      "=====================\n",
      "\n",
      "Agent Smith:\n",
      "\n",
      "Prediction cluster containing Agent Smith (Only showing characters who exist in tvtropes.clusters.txt):\n",
      "Cluster 29: Austin, Arthur Bach, Vinny, Agent Smith\n",
      "\n",
      "Groundtruth cluster containing Agent Smith (Only showing characters who exist in tvtropes.clusters.txt):\n",
      "consummate_professional: Frank Martin, The Professor, Agent Smith\n",
      "\n",
      "=====================\n",
      "\n",
      "Nancy Thompson:\n",
      "\n",
      "Prediction cluster containing Nancy Thompson (Only showing characters who exist in tvtropes.clusters.txt):\n",
      "Cluster 63: Nancy Thompson, Sharpay Evans, Mina Harker, Blue\n",
      "\n",
      "Groundtruth cluster containing Nancy Thompson (Only showing characters who exist in tvtropes.clusters.txt):\n",
      "final_girl: Ellen Ripley, Laurie Strode, Nancy Thompson, Sidney Prescott, Sarah Connor\n",
      "\n",
      "=====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "char_of_interest = [\"Darth Vader\", \"Hannibal Lecter\", \"Anakin Skywalker\", \"Agent Smith\", \"Nancy Thompson\"]\n",
    "for char in char_of_interest:\n",
    "    print(f\"{char}:\\n\")\n",
    "    print(f\"Prediction cluster containing {char} (Only showing characters who exist in tvtropes.clusters.txt):\")\n",
    "    for cluster, characters in cluster_dict.items():\n",
    "        if char in characters: print(f\"Cluster {cluster}: {', '.join(characters)}\")\n",
    "    print(f\"\\nGroundtruth cluster containing {char} (Only showing characters who exist in tvtropes.clusters.txt):\")\n",
    "    for trope, characters in grouped_by_trope.items():\n",
    "        if char in characters: print(f\"{trope}: {', '.join(characters)}\")\n",
    "    print(\"\\n=====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c23527c-9a1a-469c-afa0-64f5c92ef60a",
   "metadata": {},
   "source": [
    "### Why use the Dirichlet Persona Model:\n",
    "The model used here to cluster the characters by trope is the Dirichlet Persona Model. We attempted to use it since it was the method described in the paper: </br> Bamman, D., O’Connor, B., & Smith, N. A. (2013). Learning latent personas of film characters. Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL), 352–361."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df896f-52ed-4750-97d9-8ef198a8242b",
   "metadata": {},
   "source": [
    "### How it works:\n",
    "Before using this model we need to preprocess the movie summaries we have into character bag of words. Each character has a bag of words extracted from movie summaries. These bag of words contain attributes and agent and patient verbs, which are actions either the character took or were taken on the character. </br>\n",
    "Using these bag of words, we can create a document-term matrix (here if the same verb is once patient and once agent, it is considered as 2 different features). </br>\n",
    "Using the document-term matrix, the model associates each character with a latent persona."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa05d52e-5977-418f-9c20-4be329d47cc7",
   "metadata": {},
   "source": [
    "### Initial concerns:\n",
    "Before implementing this method, the concern was mainly the need to specify the number of clusters, and the need to manually assign a trope to each cluster. Here we attempt to simplify that by using the tvtropes.clusters.txt dataset. We could match the predicted clusters to the dataset tropes if they have a big enough intersection. Therefore we also set the number of cluster to the number of tropes in the dataset. </br>\n",
    "Another concern is the loss of context/structure as we go from a movie summary to bag of words before performing clustering with this methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a671c76c-dfda-41fb-90e3-6e510df34235",
   "metadata": {},
   "source": [
    "### Findings:\n",
    "The results of using this method are shown above. Here we considered the tvtropes.clusters.txt to be a groundtruth. </br>\n",
    "There are 131 characters for whom we have a groundtruth cluster out of a total of 72 clusters, so instead of outputing everything, we decided to highlight the results for 5 characters. </br>\n",
    "Since the predictions are simply clusters which we still did not associate to any trope, by showing the predicted cluster of a character and the \"groundtruth\" cluster, we can see if there are other matches between the predicted cluster and the groundtruth trope. </br>\n",
    "Here we see the model does gives a very poor performance. For all the characters we chose to highlight, there are no other matches between the predicted cluster and the grountruth trope. Of course re-running the code will result in different clusters and results due to randomness. Often during other runs, the model will give some clusters with 2 characters within the same cluster that share the same trope, however this is usually accompanied by multiple miss classified characters.</br>\n",
    "Due to the poor results, we decided to change our approach for trope clustering/classification, completeling abandoning this method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
